# Story 1.6: Data Storage Service (SQLite Database Setup)

## Status
Draft

## Story
**As a** developer,
**I want** a SQLite database that stores sensor readings with timestamps,
**so that** the firmware can persist data locally for later sync to mobile app.

## Acceptance Criteria
1. SQLite database file created in `firmware/data/sensor_data.db`
2. Database schema created with table `sensor_readings`:
   - `id` (INTEGER PRIMARY KEY AUTOINCREMENT)
   - `timestamp` (TEXT - ISO 8601 format)
   - `soil_moisture` (REAL - percentage 0-100)
   - `soil_temp_stemma` (REAL - Â°C from STEMMA sensor)
   - `soil_temp_ds18b20` (REAL - Â°C from DS18B20, nullable)
   - `light_lux` (REAL - lux 0-65535)
   - `air_temp` (REAL - Â°C from DHT20)
   - `air_humidity` (REAL - % RH from DHT20)
3. Python data access module (`firmware/storage.py`) with functions:
   - `insert_reading(timestamp, soil_moisture, soil_temp_stemma, soil_temp_ds18b20, light_lux, air_temp, air_humidity)`
   - `get_readings_since(timestamp)` - returns list of readings since given time
   - `get_latest_reading()` - returns most recent reading
4. Unit test script inserts 10 dummy readings, queries them back, verifies data integrity
5. Database file is persistent (survives Pi reboot)

## Tasks / Subtasks

**ðŸ¤– AI AGENT CAN EXECUTE (via SSH to Raspberry Pi):**

- [ ] Create database schema and storage module (AC: 1, 2, 3)
  - [ ] SSH into Raspberry Pi
  - [ ] Create data directory: `mkdir -p ~/opengardenlab/firmware/data`
  - [ ] Create storage module: `nano ~/opengardenlab/firmware/storage.py`
  - [ ] Implement SensorDataStore class with:
    - [ ] Database initialization and table creation
    - [ ] `insert_reading()` method with ISO 8601 timestamp generation
    - [ ] `get_readings_since(timestamp)` method with timestamp filtering
    - [ ] `get_latest_reading()` method returning most recent entry
    - [ ] `get_config()` and `update_config()` methods for device configuration
    - [ ] Proper SQLite connection handling and commit logic
  - [ ] Create indexes on `timestamp` and `device_id` columns for query performance
  - [ ] Implement `device_config` table for runtime configuration storage
  - [ ] Save and exit nano (Ctrl+X, Y, Enter)

- [ ] Implement unit test for storage module (AC: 4)
  - [ ] Create test file: `nano ~/opengardenlab/firmware/tests/test_storage.py`
  - [ ] Write unit test code:
    ```python
    #!/usr/bin/env python3
    import sys
    import os
    from datetime import datetime, timedelta

    # Add firmware directory to Python path
    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

    from storage import SensorDataStore

    def test_insert_and_query():
        """Test inserting dummy readings and querying them back"""
        print("Testing SensorDataStore...\n")

        # Use in-memory database for testing
        db = SensorDataStore(":memory:")

        # Insert 10 dummy readings with sequential timestamps
        print("Inserting 10 dummy readings...")
        base_time = datetime.utcnow()
        for i in range(10):
            timestamp = (base_time + timedelta(minutes=i*15)).isoformat() + 'Z'
            db.insert_reading(
                device_id="test-device",
                soil_moisture=45.0 + i,
                soil_temp_stemma=22.0 + (i * 0.1),
                soil_temp_ds18b20=21.5 + (i * 0.1),
                light_lux=12000 + (i * 100),
                air_temp=23.0 + (i * 0.1),
                air_humidity=55.0 + i
            )
        print("âœ“ 10 readings inserted\n")

        # Query all readings
        print("Querying all readings...")
        since_timestamp = (base_time - timedelta(hours=1)).isoformat() + 'Z'
        readings = db.get_readings_since(since_timestamp)
        assert len(readings) == 10, f"Expected 10 readings, got {len(readings)}"
        print(f"âœ“ Retrieved {len(readings)} readings\n")

        # Verify data integrity
        print("Verifying data integrity...")
        first_reading = readings[0]
        assert first_reading['device_id'] == "test-device"
        assert first_reading['soil_moisture'] == 45.0
        assert first_reading['light_lux'] == 12000
        print("âœ“ First reading data verified\n")

        # Test get_latest_reading
        print("Testing get_latest_reading...")
        latest = db.get_latest_reading()
        assert latest['soil_moisture'] == 54.0, f"Expected 54.0, got {latest['soil_moisture']}"
        assert latest['air_humidity'] == 64.0
        print("âœ“ Latest reading verified\n")

        # Test partial query (last 5 readings)
        print("Testing partial query (last 5 readings)...")
        since_timestamp = (base_time + timedelta(minutes=5*15)).isoformat() + 'Z'
        recent_readings = db.get_readings_since(since_timestamp)
        assert len(recent_readings) == 5, f"Expected 5 readings, got {len(recent_readings)}"
        print(f"âœ“ Retrieved {len(recent_readings)} recent readings\n")

        print("All tests passed! âœ“")

    if __name__ == "__main__":
        test_insert_and_query()
    ```
  - [ ] Save and exit nano (Ctrl+X, Y, Enter)
  - [ ] Make test executable: `chmod +x ~/opengardenlab/firmware/tests/test_storage.py`

- [ ] Run unit test and verify storage functionality (AC: 4)
  - [ ] Execute test: `python3 ~/opengardenlab/firmware/tests/test_storage.py`
  - [ ] Verify test passes:
    - [ ] All 10 readings inserted successfully
    - [ ] Query returns correct number of readings
    - [ ] Data integrity verified (values match inserted data)
    - [ ] Latest reading query returns most recent entry
    - [ ] Partial query (last 5 readings) works correctly
  - [ ] If test fails, debug and fix storage.py implementation
  - [ ] Document test output for story completion

- [ ] Test database persistence (AC: 5)
  - [ ] Create persistence test directory: `mkdir -p ~/opengardenlab/firmware/tests`
  - [ ] Create persistence test script: `nano ~/opengardenlab/firmware/tests/test_persistence.py`
  - [ ] Write persistence test code:
    ```python
    #!/usr/bin/env python3
    import sys
    import os
    from datetime import datetime

    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

    from storage import SensorDataStore

    # Use actual database file (not in-memory)
    db_path = os.path.expanduser("~/opengardenlab/firmware/data/test_sensor_data.db")
    db = SensorDataStore(db_path)

    # Insert a test reading
    timestamp = datetime.utcnow().isoformat() + 'Z'
    db.insert_reading(
        device_id="persistence-test",
        soil_moisture=50.0,
        soil_temp_stemma=22.5,
        soil_temp_ds18b20=21.8,
        light_lux=15000,
        air_temp=23.5,
        air_humidity=60.0
    )

    print(f"Test reading inserted at {timestamp}")
    print(f"Database file: {db_path}")
    print("\nTo verify persistence:")
    print("1. Reboot Raspberry Pi: sudo reboot")
    print("2. After reboot, run: python3 ~/opengardenlab/firmware/tests/verify_persistence.py")
    ```
  - [ ] Create verification script: `nano ~/opengardenlab/firmware/tests/verify_persistence.py`
  - [ ] Write verification code:
    ```python
    #!/usr/bin/env python3
    import sys
    import os

    sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

    from storage import SensorDataStore

    db_path = os.path.expanduser("~/opengardenlab/firmware/data/test_sensor_data.db")

    if not os.path.exists(db_path):
        print("âŒ Database file does not exist! Persistence test FAILED.")
        sys.exit(1)

    db = SensorDataStore(db_path)
    latest = db.get_latest_reading()

    if latest and latest.get('device_id') == 'persistence-test':
        print("âœ“ Database persisted across reboot!")
        print(f"Latest reading: {latest}")
    else:
        print("âŒ Reading not found! Persistence test FAILED.")
        sys.exit(1)
    ```
  - [ ] Run persistence test: `python3 ~/opengardenlab/firmware/tests/test_persistence.py`
  - [ ] Reboot Raspberry Pi: `sudo reboot`
  - [ ] After reboot, SSH back in and verify: `python3 ~/opengardenlab/firmware/tests/verify_persistence.py`
  - [ ] Confirm database file survived reboot and data is intact
  - [ ] Document persistence test results

## Dev Notes

### SQLite Database Architecture
**Database Purpose** [Source: architecture/firmware-architecture-raspberry-pi.md]
- **Local-first storage:** All sensor readings stored on Raspberry Pi for offline operation
- **Sync source:** Mobile app queries this database via Bluetooth to retrieve readings
- **Configuration store:** Device settings (sampling interval, calibration) stored in `device_config` table
- **No server required:** SQLite is embedded, no network database needed

**Database Location** [Source: AC 1]
- **Path:** `~/opengardenlab/firmware/data/sensor_data.db`
- **File system:** Stored on MicroSD card (survives power cycles)
- **Backup:** User can copy database file via SSH for backup/analysis

**SQLite Version** [Source: architecture/tech-stack.md]
- **Version:** 3.x (built-in to Python 3.9+)
- **No installation needed:** SQLite3 module included in Python standard library
- **Lightweight:** Perfect for embedded systems like Raspberry Pi

### Database Schema
**sensor_readings Table** [Source: architecture/data-models.md, AC 2]
```sql
CREATE TABLE IF NOT EXISTS sensor_readings (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    device_id TEXT NOT NULL,
    timestamp TEXT NOT NULL,  -- ISO 8601 UTC: '2025-10-02T14:30:00Z'
    soil_moisture REAL,       -- 0-100% (calibrated)
    soil_temp_stemma REAL,    -- Â°C from STEMMA Soil sensor
    soil_temp_ds18b20 REAL,   -- Â°C from DS18B20 probe (nullable - Story 1.5)
    light_lux REAL,           -- 0-65535 lux from BH1750
    air_temp REAL,            -- Â°C from DHT20
    air_humidity REAL         -- 0-100% RH from DHT20
);

CREATE INDEX IF NOT EXISTS idx_timestamp ON sensor_readings(timestamp);
CREATE INDEX IF NOT EXISTS idx_device_id ON sensor_readings(device_id);
```

**device_config Table** [Source: architecture/firmware-architecture-raspberry-pi.md]
```sql
CREATE TABLE IF NOT EXISTS device_config (
    id INTEGER PRIMARY KEY CHECK (id = 1),  -- Enforce single row
    device_id TEXT NOT NULL,
    sampling_interval_minutes INTEGER DEFAULT 15,
    soil_moisture_air_value INTEGER DEFAULT 200,    -- Calibration: air reading
    soil_moisture_water_value INTEGER DEFAULT 2000  -- Calibration: water reading
);
```
- **Single row constraint:** `CHECK (id = 1)` ensures only one config row exists
- **Updated at runtime:** Bluetooth sync can modify calibration values

### SensorDataStore Module
**Module Location** [Source: architecture/repository-structure.md]
- **File path:** `firmware/storage.py`
- **Imports:** `sqlite3`, `datetime`, `typing` (all built-in Python modules)

**Class Interface** [Source: architecture/firmware-architecture-raspberry-pi.md]
```python
class SensorDataStore:
    def __init__(self, db_path: str = "firmware/data/sensor_data.db")
    def insert_reading(device_id: str, soil_moisture: float,
                      soil_temp_stemma: float, soil_temp_ds18b20: Optional[float],
                      light_lux: float, air_temp: float, air_humidity: float)
    def get_readings_since(since_timestamp: str) -> List[Dict]
    def get_latest_reading() -> Dict
    def get_config() -> Dict
    def update_config(**kwargs)
```

**Key Methods:**
1. **`insert_reading()`** [Source: AC 3]
   - Generates ISO 8601 timestamp: `datetime.utcnow().isoformat() + 'Z'`
   - Example: `"2025-10-02T14:30:00Z"`
   - Inserts sensor data with timestamp
   - Auto-commits to database

2. **`get_readings_since(timestamp)`** [Source: AC 3]
   - Queries all readings AFTER given timestamp
   - Returns list of dictionaries (column names as keys)
   - Used by Bluetooth sync to retrieve new data
   - Ordered by timestamp ASC (oldest first)

3. **`get_latest_reading()`** [Source: AC 3]
   - Returns most recent sensor reading
   - Used for health checks and debugging
   - Returns empty dict if no readings exist

4. **`get_config()` / `update_config()`** [Source: architecture/firmware-architecture-raspberry-pi.md]
   - Retrieve/update device configuration
   - Bluetooth sync uses these to modify calibration values
   - Config changes persist in SQLite

### ISO 8601 Timestamp Format
**Standard Format** [Source: architecture/coding-standards.md]
- **UTC timestamps only:** All readings in UTC timezone (no local time)
- **Format:** `YYYY-MM-DDTHH:MM:SSZ` (Z indicates UTC)
- **Python implementation:** `datetime.utcnow().isoformat() + 'Z'`
- **Example:** `"2025-10-02T14:30:00Z"`

**Why UTC:**
- **No timezone confusion:** Mobile app and firmware always agree on time
- **Bluetooth sync:** Timestamps used to query "readings since last sync"
- **Sortable:** ISO 8601 format is lexicographically sortable (alphanumeric sort = chronological sort)

### Data Integrity and Testing
**Unit Test Requirements** [Source: AC 4]
- **Test database:** Use `:memory:` for unit tests (in-memory SQLite, no file I/O)
- **Test coverage:**
  1. Insert 10 dummy readings
  2. Query all readings (verify count = 10)
  3. Verify data integrity (values match inserted data)
  4. Test `get_latest_reading()` (verify most recent entry)
  5. Test partial query (last 5 readings using timestamp filter)

**Persistence Test** [Source: AC 5]
- **Test real database file:** Use `~/opengardenlab/firmware/data/test_sensor_data.db`
- **Procedure:**
  1. Insert test reading
  2. Reboot Raspberry Pi (`sudo reboot`)
  3. Verify database file exists after reboot
  4. Query reading, confirm data intact
- **Success criteria:** Database survives power cycle, no data loss

### Error Handling
**SQLite Best Practices** [Source: architecture/coding-standards.md]
- **Always commit:** Use `conn.commit()` after INSERT/UPDATE operations
- **Connection management:** Open connection in `__init__`, reuse for all operations
- **Nullable columns:** `soil_temp_ds18b20` is nullable (Story 1.5 sensor is optional)
- **Error logging:** Catch exceptions, log errors (Story 1.8 will add logging)

**Schema Migration** [Source: architecture/coding-standards.md]
- **MVP approach:** No automatic migrations (manual schema changes documented)
- **Post-MVP:** Consider Alembic or custom migration system
- **Breaking changes:** Document manual migration steps in firmware update guide

### Dependency on Previous Stories
- **Story 1.2 (Pi Setup):** SSH access and Python 3.9+ required
- **Story 1.4 (I2C Sensors):** Data model includes STEMMA, BH1750, DHT20 readings
- **Story 1.5 (DS18B20):** Data model includes optional DS18B20 temperature field
- **Next Story:** Story 1.7 will integrate storage module into sensor sampling service

### Expected Storage Growth
**Database Size Calculations** [Source: architecture/firmware-architecture-raspberry-pi.md]
- **15-minute sampling interval:** 96 readings/day
- **Row size:** ~120 bytes per reading (8 columns Ã— ~15 bytes average)
- **Daily growth:** 96 Ã— 120 = 11.5 KB/day
- **30-day storage:** ~345 KB (minimal MicroSD usage)
- **1-year storage:** ~4.2 MB (negligible for 16-32GB SD card)

**SQLite handles millions of rows** - No performance concerns for garden monitoring use case

### Testing
**Testing Standards for Story 1.6:**
- **Test Type:** Unit tests using in-memory database + persistence test with real database file
- **Test Location:** `~/opengardenlab/firmware/tests/test_storage.py`
- **Verification Steps:**
  1. âœ… Database schema created correctly (sensor_readings + device_config tables)
  2. âœ… Indexes created on timestamp and device_id columns
  3. âœ… `insert_reading()` stores data with ISO 8601 timestamps
  4. âœ… `get_readings_since()` filters by timestamp correctly
  5. âœ… `get_latest_reading()` returns most recent entry
  6. âœ… Data integrity verified (10 dummy readings inserted and queried back)
  7. âœ… Persistence test: Database survives Pi reboot, data intact
- **Success Criteria:** All unit tests pass, persistence test confirms database file survives reboot
- **Test Framework:** Manual test scripts (pytest integration deferred to Story 1.10 CI/CD setup)
[Source: architecture/testing-strategy.md]

## Change Log
| Date | Version | Description | Author |
|------|---------|-------------|--------|
| 2025-10-03 | 1.0 | Initial story creation | Bob (Scrum Master) |

## Dev Agent Record
*This section will be populated by the development agent during implementation*

### Agent Model Used
*To be filled by dev agent*

### Debug Log References
*To be filled by dev agent*

### Completion Notes
*To be filled by dev agent*

### File List
*To be filled by dev agent*

## QA Results
*To be filled by QA agent*
